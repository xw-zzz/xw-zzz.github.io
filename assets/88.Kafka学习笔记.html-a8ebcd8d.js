import{_ as a}from"./20220619171126-93b3d956.js";import{_ as s}from"./plugin-vue_export-helper-c27b6911.js";import{o as n,c as e,b as l}from"./app-ef0b4d9d.js";const i="/assets/20220619174409-6dc82e57.png",p={},t=l('<h2 id="概念" tabindex="-1"><a class="header-anchor" href="#概念" aria-hidden="true">#</a> 概念</h2><ul><li><p>Broker</p><ul><li>Kafka的服务端程序，可以认为一个mq节点就是一个broker</li><li>broker存储topic的数据</li></ul></li><li><p>Producer生产者</p><ul><li>创建消息Message，然后发布到MQ中</li><li>该角色将消息发布到Kafka的topic中</li></ul></li><li><p>Consumer消费者:</p><ul><li>消费队列里面的消息</li></ul></li><li><p>ConsumerGroup消费者组</p><p>同个topic, 广播发送给不同的group，一个group中只有一个consumer可以消费此消息</p></li><li><p>Topic</p><p>每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic，主题的意思</p></li><li><p>Partition分区</p><ul><li>kafka数据存储的基本单元，topic中的数据分割为一个或多个partition，每个topic至少有一个partition，是有序的</li><li>一个Topic的多个partitions, 被分布在kafka集群中的多个server上</li><li>消费者数量 &lt;=小于或者等于Partition数量</li></ul></li><li><p>Replication 副本（备胎）</p><ul><li>同个Partition会有多个副本replication ，多个副本的数据是一样的，当其他broker挂掉后，系统可以主动用副本提供服务</li><li>默认每个topic的副本都是1（默认是没有副本，节省资源），也可以在创建topic的时候指定</li><li>如果当前kafka集群只有3个broker节点，则replication-factor最大就是3了，如果创建副本为4，则会报错</li></ul></li><li><p>ReplicationLeader、ReplicationFollower</p><ul><li>Partition有多个副本，但只有一个replicationLeader负责该Partition和生产者消费者交互</li><li>ReplicationFollower只是做一个备份，从replicationLeader进行同步</li></ul></li><li><p>ReplicationManager</p><ul><li>负责Broker所有分区副本信息，Replication 副本状态切换</li></ul></li><li><p>offset</p><ul><li>每个consumer实例需要为他消费的partition维护一个记录自己消费到哪里的偏移offset</li><li>kafka把offset保存在消费端的消费者组里</li></ul><p><img src="'+a+`" alt="" loading="lazy"></p></li></ul><h2 id="docker安装" tabindex="-1"><a class="header-anchor" href="#docker安装" aria-hidden="true">#</a> Docker安装</h2><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment">## 安装ZK</span>
<span class="token function">docker</span> run <span class="token parameter variable">-d</span> <span class="token parameter variable">--name</span> zookeeper-server <span class="token punctuation">\\</span>
    <span class="token parameter variable">--network</span><span class="token operator">=</span>host <span class="token punctuation">\\</span>
    <span class="token parameter variable">--restart</span><span class="token operator">=</span>always <span class="token punctuation">\\</span>
    <span class="token parameter variable">-e</span> <span class="token assign-left variable">ALLOW_ANONYMOUS_LOGIN</span><span class="token operator">=</span>yes <span class="token punctuation">\\</span>
    bitnami/zookeeper:latest
    
<span class="token comment">##安装kafka服务端    </span>
<span class="token function">docker</span> run <span class="token parameter variable">-d</span> <span class="token parameter variable">--name</span> kafka-server <span class="token punctuation">\\</span>
    <span class="token parameter variable">--network</span><span class="token operator">=</span>host <span class="token punctuation">\\</span>
    <span class="token parameter variable">--restart</span><span class="token operator">=</span>always <span class="token punctuation">\\</span>
    <span class="token parameter variable">-e</span> <span class="token assign-left variable">ALLOW_PLAINTEXT_LISTENER</span><span class="token operator">=</span>yes <span class="token punctuation">\\</span>
    <span class="token parameter variable">-e</span> <span class="token assign-left variable">KAFKA_CFG_ZOOKEEPER_CONNECT</span><span class="token operator">=</span><span class="token number">127.0</span>.0.1:2181 <span class="token punctuation">\\</span>
    bitnami/kafka:latest

<span class="token comment">## 安装kafka客户端</span>
<span class="token function">docker</span> run <span class="token parameter variable">-it</span> <span class="token parameter variable">--rm</span> <span class="token punctuation">\\</span>
    <span class="token parameter variable">--network</span><span class="token operator">=</span>host <span class="token punctuation">\\</span>
    <span class="token parameter variable">-e</span> <span class="token assign-left variable">KAFKA_CFG_ZOOKEEPER_CONNECT</span><span class="token operator">=</span><span class="token number">127.0</span>.0.1:2181 <span class="token punctuation">\\</span>
    bitnami/kafka:latest kafka-topics.sh <span class="token parameter variable">--list</span>  --bootstrap-server <span class="token number">127.0</span>.0.1:9092
    
<span class="token function">docker</span> run <span class="token parameter variable">-d</span> <span class="token parameter variable">--network</span><span class="token operator">=</span>host <span class="token parameter variable">--name</span><span class="token operator">=</span>kafka-manager <span class="token parameter variable">-p</span> <span class="token number">9000</span>:9000 <span class="token parameter variable">-e</span> <span class="token assign-left variable">ZK_HOSTS</span><span class="token operator">=</span><span class="token string">&quot;192.168.0.110:2181&quot;</span> sheepkiller/kafka-manager:2.5.1
    
<span class="token function">docker</span> run  <span class="token parameter variable">-d</span>  <span class="token parameter variable">--network</span><span class="token operator">=</span>host  <span class="token parameter variable">-v</span> /opt/zk:/home/michael/opt/zookeeper/data   <span class="token parameter variable">--name</span> zookeeper wurstmeister/zookeeper 
    
<span class="token function">docker</span> run <span class="token parameter variable">-d</span>  <span class="token parameter variable">--network</span><span class="token operator">=</span>host  <span class="token parameter variable">--name</span> kafka <span class="token punctuation">\\</span>
<span class="token parameter variable">-p</span> <span class="token number">9092</span>:9092 <span class="token punctuation">\\</span>
<span class="token parameter variable">-e</span> <span class="token assign-left variable">KAFKA_BROKER_ID</span><span class="token operator">=</span><span class="token number">0</span> <span class="token punctuation">\\</span>
<span class="token parameter variable">-e</span> <span class="token assign-left variable">KAFKA_ZOOKEEPER_CONNECT</span><span class="token operator">=</span><span class="token number">127.0</span>.0.1:2181 <span class="token punctuation">\\</span>
<span class="token parameter variable">-e</span> <span class="token assign-left variable">KAFKA_LOG_RETENTION_HOURS</span><span class="token operator">=</span><span class="token number">5</span> <span class="token punctuation">\\</span>
<span class="token parameter variable">-e</span> <span class="token assign-left variable">KAFKA_ADVERTISED_LISTENERS</span><span class="token operator">=</span>PLAINTEXT://192.168.0.110:9092 <span class="token punctuation">\\</span>
<span class="token parameter variable">-e</span> <span class="token assign-left variable">KAFKA_LISTENERS</span><span class="token operator">=</span>PLAINTEXT://192.168.0.110:9092 wurstmeister/kafka    

<span class="token function">docker</span> run <span class="token parameter variable">-d</span> <span class="token parameter variable">--network</span><span class="token operator">=</span>host <span class="token punctuation">\\</span>
    <span class="token parameter variable">-p</span> <span class="token number">8080</span>:8080 <span class="token punctuation">\\</span>
    <span class="token parameter variable">-v</span> /opt/kafka-map/data:/usr/local/kafka-map/data <span class="token punctuation">\\</span>
    <span class="token parameter variable">-e</span> <span class="token assign-left variable">DEFAULT_USERNAME</span><span class="token operator">=</span>admin <span class="token punctuation">\\</span>
    <span class="token parameter variable">-e</span> <span class="token assign-left variable">DEFAULT_PASSWORD</span><span class="token operator">=</span>admin <span class="token punctuation">\\</span>
    <span class="token parameter variable">--name</span> kafka-map <span class="token punctuation">\\</span>
    <span class="token parameter variable">--restart</span> always dushixiang/kafka-map:latest
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="kafka数据存储流程" tabindex="-1"><a class="header-anchor" href="#kafka数据存储流程" aria-hidden="true">#</a> Kafka数据存储流程</h2><ul><li><p><strong>Partition</strong></p><ul><li><p>topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列</p></li><li><p>是以文件夹的形式存储在具体Broker本机上</p><p><img src="`+i+'" alt="" loading="lazy"></p></li></ul></li><li><p><strong>LEO（LogEndOffset）</strong></p><ul><li>表示每个partition的log最后一条Message的位置。</li></ul></li><li><p><strong>HW（HighWatermark）</strong></p><ul><li>表示partition各个replicas数据间同步且一致的offset位置，即表示allreplicas已经commit的位置</li><li>HW之前的数据才是Commit后的，对消费者才可见</li><li>ISR集合里面最小leo</li></ul></li><li><p><strong>offset</strong>：</p><ul><li>每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中</li><li>partition中的每个消息都有一个连续的序列号叫做offset，用于partition唯一标识一条消息</li><li>可以认为offset是partition中Message的id</li></ul></li><li><p><strong>Segment</strong>：每个partition又由多个segment file组成；</p><ul><li>segment file 由2部分组成，分别为index file和data file（log file），</li><li>两个文件是一一对应的，后缀”.index”和”.log”分别表示索引文件和数据文件</li><li>命名规则：partition的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset+1</li></ul></li><li><p>Kafka高效文件存储设计特点：</p><ul><li>Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。</li><li>通过索引信息可以快速定位message</li><li>producer生产数据，要写入到log文件中，写的过程中一直追加到文件末尾，为顺序写，官网数据表明。同样的磁盘，顺序写能到600M/S，而随机写只有100K/S</li></ul></li></ul>',6),r=[t];function o(c,k){return n(),e("div",null,r)}const v=s(p,[["render",o],["__file","88.Kafka学习笔记.html.vue"]]);export{v as default};
